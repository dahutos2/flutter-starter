## UC01 画像と結果の文字列のペアをまとめて登録し、学習を実行する

### 1. ローカルから CSV ファイルを S3 にアップロードするバッチスクリプト

ローカルから CSV ファイルを S3 にアップロードするバッチスクリプト(`upload_to_s3.bat`)を作成します。

```bash
@echo off
setlocal

REM S3バケット名とCSVファイルのパスを設定
set AWS_BUCKET=ogiri-training-data-bucket
set CSV_FILE=path\to\your\train_data.csv

REM CSVファイルをS3にアップロード
aws s3 cp %CSV_FILE% s3://%AWS_BUCKET%/

endlocal
```

### 2. IAM ポリシーの作成

#### 2.1. トレーニングジョブ開始する Lambda 用のポリシーの作成

1. **AWS マネジメントコンソール**にログインし、**IAM**ダッシュボードに移動します。
2. 左側のメニューから「**ポリシー**」を選択し、「**ポリシーを作成**」ボタンをクリックします。
3. **JSON**タブを選択し、以下のポリシーを貼り付けます:

<details><summary>詳細を開く</summary>

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:GetObject"
            ],
            "Resource": [
                "arn:aws:s3:::ogiri-training-data-bucket/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "dynamodb:GetItem",
                "dynamodb:PutItem",
                "dynamodb:Query"
            ],
            "Resource": [
                "arn:aws:dynamodb:ap-northeast-1:765231401377:table/OgiriTrainingDataTable"
            ]
        },
        {
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "arn:aws:iam::765231401377:role/SageMakerOgiriTrainingJobRole"
        },
        {
            "Effect": "Allow",
            "Action": [
                "rekognition:DetectLabels",
                "rekognition:DetectText"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "sagemaker:CreateTrainingJob",
                "sagemaker:DescribeTrainingJob"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "logs:CreateLogGroup",
                "logs:CreateLogStream",
                "logs:PutLogEvents"
            ],
            "Resource": [
                "arn:aws:logs:ap-northeast-1:765231401377:log-group:/aws/lambda/*"
            ]
        }
    ]
}
```

</details>

4. 「**次のステップ: タグ**」をクリックし、任意のタグを追加します（省略可能）。
5. 「**次のステップ: 確認**」をクリックし、ポリシーに名前（例: `LambdaStartOgiriTrainingJobPolicy`）と説明を入力して「**ポリシーの作成**」をクリックします。

#### 2.2. トレーニングジョブ終了後の Lambda 用のポリシーの作成

1. [2.1](#21-トレーニングジョブ開始するlambda用のポリシーの作成)同様の手順で以下のポリシー（`LambdaEndOgiriTrainingJobPolicy`）を作成する

<details><summary>詳細を開く</summary>

```json
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Effect": "Allow",
			"Action": [
				"sagemaker:CreateModel",
				"sagemaker:CreateEndpointConfig",
				"sagemaker:CreateEndpoint",
				"sagemaker:DescribeTrainingJob"
			],
			"Resource": "*"
		},
		{
			"Effect": "Allow",
			"Action": "iam:PassRole",
			"Resource": "arn:aws:iam::765231401377:role/SageMakerOgiriTrainingJobRole"
		},
		{
			"Effect": "Allow",
			"Action": [
				"logs:CreateLogGroup",
				"logs:CreateLogStream",
				"logs:PutLogEvents"
			],
			"Resource": [
				"arn:aws:logs:ap-northeast-1:765231401377:log-group:/aws/lambda/*"
			]
		}
	]
}
```

</details>

#### 2.3. SageMaker 用のポリシーの作成

1. [2.1](#21-トレーニングジョブ開始するlambda用のポリシーの作成)同様の手順で以下のポリシー（`SageMakerOgiriTrainingJobPolicy`）を作成する

<details><summary>詳細を開く</summary>

```json
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Effect": "Allow",
			"Action": [
				"s3:GetObject",
				"s3:PutObject",
				"s3:ListBucket"
			],
			"Resource": [
				"arn:aws:s3:::ogiri-training-data-bucket",
				"arn:aws:s3:::ogiri-training-data-bucket/*"
			]
		},
		{
			"Effect": "Allow",
			"Action": [
				"dynamodb:PutItem",
				"dynamodb:GetItem",
				"dynamodb:Scan",
				"dynamodb:Query"
			],
			"Resource": "arn:aws:dynamodb:ap-northeast-1:765231401377:table/OgiriTrainingDataTable"
		},
		{
			"Effect": "Allow",
			"Action": "iam:PassRole",
			"Resource": "arn:aws:iam::765231401377:role/SageMakerOgiriTrainingJobRole"
		},
		{
			"Effect": "Allow",
			"Action": [
				"logs:CreateLogGroup",
				"logs:CreateLogStream",
				"logs:PutLogEvents"
			],
			"Resource": "arn:aws:logs:ap-northeast-1:765231401377:log-group:/aws/sagemaker/*"
		}
	]
}
```

</details>

### 3. IAM ロールの作成

#### 3.1. トレーニングジョブ開始する Lambda 用のロールの作成

1. IAM ダッシュボードの左側のメニューから「**ロール**」を選択し、「**ロールを作成**」ボタンをクリックします。
2. 「**信頼されたエンティティのタイプを選択**」画面で「**AWS サービス**」を選択し、「**Lambda**」を選択します。「**次のステップ**」をクリックします。
3. 先ほど作成したポリシー（`LambdaStartOgiriTrainingJobPolicy`）を検索し、選択して「**次のステップ**」をクリックします。
4. ロールに名前（例: `LambdaStartOgiriTrainingJobRole`）を付けて「**ロールの作成**」をクリックします。

#### 3.2. トレーニングジョブ終了後の Lambda 用のロールの作成

1. [3.1](#31-トレーニングジョブ開始するlambda用のロールの作成)と同様の手順で以下の名前とポリシーのロールを作成する
   - ポリシー名: `LambdaEndOgiriTrainingJobPolicy`
   - ロール名: `LambdaEndOgiriTrainingJobRole`
 
#### 3.3. SageMaker 用のロールの作成

1. IAM ダッシュボードの左側のメニューから「**ロール**」を選択し、「**ロールを作成**」ボタンをクリックします。
2. 「**信頼されたエンティティのタイプを選択**」画面で「**AWS サービス**」を選択し、「**SageMaker**」を選択します。「**次のステップ**」をクリックします。
3. デフォルトポリシー（`AmazonSageMakerFullAccess`）を選択して「**次のステップ**」をクリックします。
4. ロールに名前（例: `SageMakerOgiriTrainingJobRole`）を付けて「**ロールの作成**」をクリックします。
5. 作成したロール（`SageMakerOgiriTrainingJobRole`）の詳細ページから「**許可の追加**」をクリックします。
6. `SageMakerOgiriTrainingJobPolicy`を追加する

### 4. IAM ユーザーに権限を追加

#### 4.1. IAM ユーザーに必要なポリシーを作成

1. **AWS マネジメントコンソール**にログインし、**IAM**ダッシュボードに移動します。
2. 左側のメニューから「**ポリシー**」を選択し、「**ポリシーを作成**」ボタンをクリックします。
3. **JSON**タブを選択し、以下のポリシーを貼り付けます:

<details><summary>詳細を開く</summary>

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:*",
        "codecommit:*",
        "codebuild:*",
        "codepipeline:*",
        "iam:PassRole",
        "iam:CreateRole",
        "iam:AttachRolePolicy",
        "iam:PutRolePolicy",
        "iam:GetRole",
        "iam:ListRolePolicies",
        "iam:DeleteRolePolicy"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "cloudformation:CreateStack",
        "cloudformation:UpdateStack",
        "cloudformation:DeleteStack",
        "cloudformation:DescribeStacks",
        "cloudformation:DescribeStackResources",
        "cloudformation:DescribeStackEvents",
        "cloudformation:GetTemplate",
        "cloudformation:ValidateTemplate"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:Query",
        "dynamodb:Scan",
        "dynamodb:UpdateItem"
      ],
      "Resource": [
        "arn:aws:dynamodb:ap-northeast-1:765231401377:table/OgiriTrainingDataTable",
        "arn:aws:dynamodb:ap-northeast-1:765231401377:table/OgiriResultsTable"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "rekognition:DetectLabels",
        "rekognition:DetectText"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "sagemaker:CreateTrainingJob",
        "sagemaker:DescribeTrainingJob",
        "sagemaker:CreateModel",
        "sagemaker:CreateEndpointConfig",
        "sagemaker:CreateEndpoint",
        "sagemaker:InvokeEndpoint"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": [
        "arn:aws:logs:ap-northeast-1:765231401377:log-group:/aws/lambda/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "lambda:InvokeFunction"
      ],
      "Resource": "arn:aws:lambda:ap-northeast-1:765231401377:function:*"
    }
  ]
}
```

</details>

4. 「**次のステップ: タグ**」をクリックし、任意のタグを追加します（省略可能）。
5. 「**次のステップ: 確認**」をクリックし、ポリシーに名前（例: `UserOgiriTrainingJobPolicy`）と説明を入力して「**ポリシーの作成**」をクリックします。

#### 4.2. IAM ユーザーに必要なポリシーを追加

1. 左側のメニューから「**ユーザー**」を選択し、作成済みのユーザのリンクをクリックします。
2. 「**許可**」タブの「**許可ポリシー**」画面で「**許可を追加**」をクリックし、「**ポリシーを直接アタッチする**」を選択します。
3. 先ほど作成したポリシー（`UserOgiriTrainingJobPolicy`）を検索し、選択して「**次へ**」をクリックし、「**許可を追加**」をクリックします。

### 5. S3 バケットの設定

1. **S3**ダッシュボードに移動し、デフォルトの設定で`ogiri-training-data-bucket`を作成します。
2. バケットの「**プロパティ**」タブを開き、下にスクロールして「**イベント通知**」セクションを見つけます。
3. 「**イベント通知を追加**」をクリックし、名前を入力します（例: `OgiriCSVUploadEvent`）。
4. 「**イベントタイプ**」で「**すべてのオブジェクト作成イベント**」を選択します。
5. 「**プレフィックス**」と「**サフィックス**」を設定して、CSV ファイルに限定します（例: `サフィックス: .csv`）。
6. 「**Lambda 関数**」セクションで、「**Lambda 関数の選択**」から先ほど作成した関数（`StartOgiriTrainingJob`）を選択します。
7. 「**保存**」をクリックします。

### 6. DynamoDB テーブルの作成

1. **DynamoDB**ダッシュボードに移動し、「**テーブルを作成**」をクリックします。
2. テーブル名を入力します（例: `OgiriTrainingDataTable`）。
3. **プライマリキー**として、以下を設定します:
   - **パーティションキー**: `ImageKey`（タイプ：文字列）
   - **ソートキー**: `ExpectedResult`（タイプ：文字列）
4. **その他の設定**の**プロビジョニングモード**は「オンデマンドキャパシティーモード」を選択します	
（または、必要に応じてプロビジョンドキャパシティーモードを選択し、読み取り/書き込みキャパシティーユニットを設定します）。
5. 「**テーブルの作成**」をクリックします。

| 設定項目               | 設定値                           |
| ---------------------- | -------------------------------- |
| テーブル名             | OgiriTrainingDataTable           |
| パーティションキー     | ImageKey（タイプ：文字列）       |
| ソートキー             | ExpectedResult（タイプ：文字列） |
| プロビジョニングモード | オンデマンドキャパシティーモード |

### 7. SageMaker の設定
 
#### 7.1. `requirements.txt`ファイルの作成

ローカル環境で`requirements.txt`ファイルを作成します。例えば以下の内容にします。

```txt
torch==1.8.1              # ニューラルネットワークの構築と学習のためのPyTorchフレームワーク
torchvision==0.9.1        # 画像変換と事前学習済みモデルのためのPyTorch visionライブラリ
transformers==4.5.1       # GPT-2のような事前学習済みモデルを使用するためのHugging Faceライブラリ
Pillow==8.2.0             # 画像の読み込み、変換、保存のための画像処理ライブラリ
```

#### 7.2. トレーニングスクリプトの準備

`training_script.py`を作成する

<details><summary>詳細をクリック</summary>

```python
import subprocess
import sys

# requirements.txtをインストール
subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-r', '/opt/ml/code/requirements.txt'])

import logging
import boto3
import os
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from transformers import GPT2Tokenizer, GPT2LMHeadModel
from PIL import Image
import argparse

# CloudWatch Logsの設定
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 定数の定義
EMBEDDING_DIM = 256

# 画像特徴抽出モデル（ResNet）
class EncoderCNN(nn.Module):
    def __init__(self, embed_size):
        super(EncoderCNN, self).__init__()
        # 事前学習済みのResNet50モデルを読み込む
        resnet = models.resnet50(pretrained=True)
        # 最後の全結合層を除去
        modules = list(resnet.children())[:-1]
        self.resnet = nn.Sequential(*modules)
        # 埋め込み層
        self.linear = nn.Linear(resnet.fc.in_features, embed_size)
        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)
        self.dropout = nn.Dropout(p=0.5)
        
    def forward(self, images):
        # 画像から特徴を抽出
        with torch.no_grad():
            features = self.resnet(images)
        features = features.reshape(features.size(0), -1)
        features = self.bn(self.linear(features))
        features = self.dropout(features)
        return features
    
# GPT-2を使ったキャプション生成
class DecoderRNN(nn.Module):
    def __init__(self, embed_size):
        super(DecoderRNN, self).__init__()
        # GPT-2トークナイザとモデルの読み込み
        self.tokenizer = GPT2Tokenizer.from_pretrained("rinna/japanese-gpt2-medium")
        self.model = GPT2LMHeadModel.from_pretrained("rinna/japanese-gpt2-medium")
        self.fc = nn.Linear(embed_size * 2, embed_size)  # 画像特徴、ラベル、信頼度、テキストの結合
    
    def forward(self, features, captions, label_texts, confidences, detected_text):
        # 文字列をエンコード
        label_indices = self.tokenizer.encode(" ".join(label_texts), add_special_tokens=False)
        text_indices = self.tokenizer.encode(detected_text, add_special_tokens=False)

        # キャプションをトークナイズし、テンソル形式に変換
        inputs = self.tokenizer(captions, return_tensors="pt", padding=True, truncation=True)
        # ラベルのインデックスをトークンの埋め込みに変換し、デバイスに移動
        label_embeddings = self.model.transformer.wte(torch.tensor(label_indices).to(features.device))
        # 信頼度をテンソルに変換し、ラベル埋め込みのサイズに拡張
        confidences = torch.tensor(confidences).to(features.device).unsqueeze(1).expand(-1, label_embeddings.size(1))
        # 検出されたテキストのインデックスをトークンの埋め込みに変換し、デバイスに移動
        text_embeddings = self.model.transformer.wte(torch.tensor(text_indices).to(features.device))
        # 画像特徴、ラベル埋め込み、信頼度、テキスト埋め込みを結合
        combined_features = torch.cat((features, label_embeddings, confidences, text_embeddings), dim=1)

        # 結合された特徴を全結合層に入力
        combined_features = self.fc(combined_features)
        # トークナイズされたキャプションを入力にして、モデルで前向き伝播を実行
        outputs = self.model(inputs_embeds=combined_features, labels=inputs["input_ids"])
        # 損失と出力ロジットを返す
        return outputs.loss, outputs.logits


    def sample(self, features, label_texts, confidences, detected_text):
        # 文字列をエンコード
        label_indices = self.tokenizer.encode(" ".join(label_texts), add_special_tokens=False)
        text_indices = self.tokenizer.encode(detected_text, add_special_tokens=False)

        # 特徴から大喜利のテキストを生成
        # 初期シーケンスとして「大喜利:」をエンコードし、テンソル形式に変換してデバイスに移動
        input_ids = self.tokenizer.encode("大喜利:", return_tensors="pt").to(features.device)
        # ラベルのインデックスをトークンの埋め込みに変換し、デバイスに移動
        label_embeddings = self.model.transformer.wte(torch.tensor(label_indices).to(features.device))
        # 信頼度をテンソルに変換し、ラベル埋め込みのサイズに拡張
        confidences = torch.tensor(confidences).to(features.device).unsqueeze(1).expand(-1, label_embeddings.size(1))
        # 検出されたテキストのインデックスをトークンの埋め込みに変換し、デバイスに移動
        text_embeddings = self.model.transformer.wte(torch.tensor(text_indices).to(features.device))
        # 画像特徴、ラベル埋め込み、信頼度、テキスト埋め込みを結合
        combined_features = torch.cat((features, label_embeddings, confidences, text_embeddings), dim=1)

        # 結合された特徴を全結合層に入力
        combined_features = self.fc(combined_features)
        # input_ids を使用してテキスト生成
        outputs = self.model.generate(input_ids=input_ids, max_length=50, num_return_sequences=1)
        # 生成されたテキストをデコードして返す
        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)

# データセットクラスの定義
class OgiriDataset(Dataset):
    def __init__(self, training_data_dir, dynamodb_table_name, dynamodb_client):
        self.training_data_dir = training_data_dir
        self.dynamodb_table_name = dynamodb_table_name
        self.dynamodb_client = dynamodb_client
        # DynamoDBからデータをロード
        self.data = self._load_data_from_dynamodb()
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),  # 画像サイズの変更
            transforms.ToTensor(),  # テンソルに変換
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # 正規化
        ])
        logger.info(f"DynamoDBから{len(self.data)}個のデータをロードしました。")

    def _load_data_from_dynamodb(self):
        # DynamoDBのデータをページネーションで取得
        paginator = self.dynamodb_client.get_paginator('scan')
        response_iterator = paginator.paginate(TableName=self.dynamodb_table_name)
        data = []
        for page in response_iterator:
            data.extend(page['Items'])
        return data

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # 画像とラベルを取得
        item = self.data[idx]
        image_key = item['ImageKey']['S']
        image_path = os.path.join(self.training_data_dir, image_key)
        image = Image.open(image_path).convert('RGB')
        image = self.transform(image)
        expected_result = item['ExpectedResult']['S']
        labels = item['Labels']['L'] # Rekognitionのラベル情報
        detected_text = item.get('DetectedText', {}).get('S', '') # Rekognitionの画像内のテキストを情報
        label_texts, confidences = self.extract_labels_and_confidences(labels)
        
        return image, expected_result, label_texts, confidences, detected_text

    def extract_labels_and_confidences(self, labels):
        label_texts = [label['M']['Name']['S'] for label in labels]
        confidences = [float(label['M']['Confidence']['N']) for label in labels]
        return label_texts, confidences

# トレーニング関数
def train(args):
    # トレーニングデータのディレクトリとDynamoDBテーブル名を設定
    training_data_dir = '/opt/ml/input/data/training'
    dynamodb_table_name = os.environ['DYNAMODB_TABLE_NAME']
    dynamodb_client = boto3.client('dynamodb')
   
    batch_size = args.batch_size
    num_epochs = args.epochs
    learning_rate = args.learning_rate
   
    # データセットとデータローダの設定
    dataset = OgiriDataset(training_data_dir, dynamodb_table_name, dynamodb_client)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
  
    # モデルの定義
    encoder = EncoderCNN(EMBEDDING_DIM)
    decoder = DecoderRNN(EMBEDDING_DIM)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    encoder.to(device)
    decoder.to(device)

    # 最適化関数の定義
    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)

    # トレーニング開始
    logger.info("トレーニングを開始します")
    for epoch in range(num_epochs):
        logger.info(f"Epoch {epoch+1}/{num_epochs} started")
        for i, (images, expected_results, label_texts, confidences, detected_text) in enumerate(dataloader):
            images = images.to(device)
            confidences = torch.tensor(confidences).to(device)

            features = encoder(images)
            optimizer.zero_grad()
            
            loss, _ = decoder(features, expected_results, label_texts, confidences, detected_text)
            loss.backward()
            optimizer.step()
            
            if i % 100 == 0:
                logger.info(f"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], Loss: {loss.item():.4f}")

    # モデルの保存
    torch.save(encoder.state_dict(), '/opt/ml/model/encoder.ckpt')
    torch.save(decoder.state_dict(), '/opt/ml/model/decoder.ckpt')
    logger.info("トレーニングが完了し、モデルを保存しました")

if __name__ == '__main__':
    # コマンドライン引数の解析
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--learning_rate', type=float, default=0.001)
    args = parser.parse_args()
    train(args)
```

</details>

#### 7.4. `requirements.txt`を S3 にアップロード

1. AWS マネジメントコンソールで「**S3**」サービスに移動します。
2. アップロードしたいバケット（例: `ogiri-training-data-bucket`）を選択します。
3. フォルダを作成で、「`training-code/`」フォルダを作成します。
4. 「**オブジェクトをアップロード**」をクリックし、「`training-code/`」フォルダに`requirements.txt`をアップロードします。

#### 7.5. トレーニングスクリプトを S3 にアップロード

1. `ogiri-training-data-bucket/training-code/`で「**オブジェクトをアップロード**」をクリックし、`training_script.py`をアップロードします。

### 8. トレーニングジョブ開始する Lambda 関数の作成

#### 8.1. Lambda 関数の作成

1. Lambda ダッシュボードに移動し、「**関数の作成**」をクリックします。
2. 「**一から作成**」を選択し、関数名（例: `StartOgiriTrainingJob`）を入力し、ランタイムを Python 3.8 に設定します。
3. 実行ロールには「**既存のロールを使用する**」を選択し、`LambdaStartOgiriTrainingJobRole`を選択します。
4. 「**関数の作成**」をクリックします。

#### 8.2. Lambda 関数にコードを追加

<details><summary>詳細をクリック</summary>

```python
import json
import boto3
import csv
import requests
from datetime import datetime
import uuid
from botocore.exceptions import NoCredentialsError, ClientError
import logging

# CloudWatch Logsの設定
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

s3 = boto3.client('s3')
rekognition = boto3.client('rekognition')
dynamodb = boto3.resource('dynamodb')
sagemaker = boto3.client('sagemaker')
events = boto3.client('events')

def lambda_handler(event, context):
    try:
        # イベントからバケット名とオブジェクトキーを取得
        bucket = event.get('bucket')
        key = event.get('key')

        if not bucket or not key:
            raise ValueError("バケットとキーはイベントで指定してください。")

        # S3からCSVファイルを取得
        csv_file = s3.get_object(Bucket=bucket, Key=key)
        csv_content = csv_file['Body'].read().decode('utf-8').splitlines()
        csv_reader = csv.reader(csv_content)

        # 先頭行(タイトル行)がスキップする
        next(csv_reader)

        # DynamoDBに学習用のデータを登録する
        table = dynamodb.Table('OgiriTrainingDataTable')

        logger.info("学習用のデータの登録を開始します。")
        for row in csv_reader:
            image_url, expected_result = row

            try:
                image_key = image_url.split('/')[-1]
                image_path = f"images/{image_key}" # images ディレクトリに配置

                # DynamoDBに既にデータが存在するか確認
                response = table.get_item(Key={'ImageKey': image_key, 'ExpectedResult': expected_result})
                if 'Item' in response:
                    logger.info(f"{image_url}は既に処理されています。")
                    continue

                # Rekognitionを使用して画像を分析する
                dynamodb_labels = None

                # Rekognitionを使用して画像内のテキストを検出
                detected_text = None

                # 同じ画像が存在するかを確認する
                labels_response = table.query(
                    KeyConditionExpression=boto3.dynamodb.conditions.Key('ImageKey').eq(image_key)
                )

                # 同じ画像が存在する場合は、DynamoDBの分析結果を使用する
                if labels_response['Items']:
                    dynamodb_labels = labels_response['Items'][0]['Labels']
                    detected_text = labels_response['Items'][0]['DetectedText']
                else:
                    # 画像が存在しない場合は登録する

                    # グローバルなURLから画像をダウンロード
                    image_data = requests.get(image_url).content

                    # ダウンロードした画像をS3にアップロード
                    s3.put_object(Bucket=bucket, Key=image_path, Body=image_data)
                    logger.info(f"S3に{image_key}を登録しました。")

                    # 画像を分析
                    rekognition_response = rekognition.detect_labels(
                        Image={'S3Object': {'Bucket': bucket, 'Name': image_path}},
                        MaxLabels=10
                    )
                    rekognition_labels = [{"Name": label['Name'], "Confidence": label['Confidence']} for label in rekognition_response['Labels']]

                    # DynamoDBに保存する形式に変換
                    dynamodb_labels = [{"M": {"Name": {"S": label["Name"]}, "Confidence": {"N": str(label["Confidence"])}}} for label in rekognition_labels]

                    # 画像内のテキストを検出
                    text_detection_response = rekognition.detect_text(
                        Image={'S3Object': {'Bucket': bucket, 'Name': image_path}}
                    )
                    detected_texts = [text['DetectedText'] for text in text_detection_response['TextDetections']]
                    detected_text = " ".join(detected_texts) if detected_texts else None

                # DynamoDBに画像URLと期待結果を保存
                table = dynamodb.Table('OgiriTrainingDataTable')
                item = {
                    'ImageKey': {'S': image_key},
                    'ExpectedResult': {'S': expected_result},
                    'Labels': {'L': dynamodb_labels},
                }

                # 画像内にテキストがある場合だけ登録する
                if detected_text:
                    item['DetectedText'] = {'S': detected_text}

                logger.info(f"{image_key}をDBに登録しました。")
            except requests.exceptions.RequestException as e:
                logger.error(f"{image_url}からの画像のダウロードに失敗しました: {str(e)}")
            except ClientError as e:
                logger.error(f"{image_url}の登録に失敗しました: {str(e)}")

        # SageMakerトレーニングジョブの作成
        now = datetime.now().strftime('%Y%m%d-%H%M%S')
        training_job_name = f'ogiri-training-job-{now}'
        response = sagemaker.create_training_job(
            TrainingJobName=training_job_name,
            HyperParameters={
                'batch_size': '32',
                'epochs': '10',
                'learning_rate': '0.001',
            },
            AlgorithmSpecification={
                'TrainingImage': '763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/pytorch-training:1.6.0-cpu-py36-ubuntu16.04',
                'MetricDefinitions': [
                {'Name': 'validation:error', 'Regex': 'validation:error=(.*)'}
                ],
                'TrainingInputMode': 'File',
                'EnableSageMakerMetricsTimeSeries': True,
            },
            RoleArn='arn:aws:iam::765231401377:role/SageMakerOgiriTrainingJobRole',
            InputDataConfig=[
                {
                'ChannelName': 'training',
                'DataSource': {
                    'S3DataSource': {
                    'S3DataType': 'S3Prefix',
                    'S3Uri': 's3://ogiri-training-data-bucket/images/',
                    'S3DataDistributionType': 'FullyReplicated'
                    }
                },
                'ContentType': 'application/json',
                'InputMode': 'File'
                }
            ],
            OutputDataConfig={
                'S3OutputPath': 's3://ogiri-training-data-bucket/output/'
            },
            ResourceConfig={
                'InstanceType': 'ml.m5.large',
                'InstanceCount': 1,
                'VolumeSizeInGB': 50
            },
            StoppingCondition={
                'MaxRuntimeInSeconds': 86400
            },
            Environment={
                'DYNAMODB_TABLE_NAME': 'OgiriTrainingDataTable',
                'SAGEMAKER_SUBMIT_DIRECTORY': 's3://ogiri-training-data-bucket/training-code/',
                'SAGEMAKER_PROGRAM': 'training_script.py'
            }
        )

        logger.info("トレーニングジョブの開始に成功しました。")

        # CloudWatch Event ルールを動的に作成
        rule_name = f'OgiriTrainingJobCompletionRule-{now}'
        event_pattern = {
            "source": ["aws.sagemaker"],
            "detail-type": ["SageMaker Training Job State Change"],
            "detail": {
                "TrainingJobName": [training_job_name],
                "TrainingJobStatus": ["Completed"]
            }
        }

        # ルールを作成
        events.put_rule(
            Name=rule_name,
            EventPattern=json.dumps(event_pattern),
            State='ENABLED'
        )

        # ルールにターゲットとしてLambda関数を追加
        target_id = f'target-{uuid.uuid4()}'
        events.put_targets(
            Rule=rule_name,
            Targets=[
                {
                    'Id': target_id,
                    'Arn': 'arn:aws:lambda:ap-northeast-1:765231401377:function:EndOgiriTrainingJob'
                }
            ]
        )

        logger.info(f"CloudWatch Event Rule {rule_name} を作成し、Lambdaターゲットを設定しました。")

        return {
            'statusCode': 200,
            'body': json.dumps('トレーニングジョブの開始に成功しました。')
        }
    except NoCredentialsError:
        logger.error("権限がないです。")
        return {
            'statusCode': 403,
            'body': '権限がないです。'
        }
    except Exception as e:
        logger.error(f"予期せぬ例外: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps(f"予期せぬ例外: {str(e)}")
        }
```

</details>

#### 8.3. テストイベントの設定

1. 「**テスト**」ボタンをクリックし、テストイベントを作成します。以下のような JSON を使用します
2. [トレーニングジョブ終了後の lambda 関数の作成](#10-トレーニングジョブ終了後のlambda関数の作成)完了後にテストする

```json
{
	"bucket": "ogiri-training-data-bucket",
	"key": "train_data.csv"
}
```

#### 8.4. 必要なパッケージをインストールし、レイヤーを作成

1. ローカル環境で以下のような内容の`requirements.txt`ファイルを作成します。

```text
requests
```

2. コマンドプロンプトまたは PowerShell を開き、以下のコマンドを実行してレイヤーを作成します

```bash
mkdir python
pip install -r requirements.txt -t python/
"C:\Program Files\7-Zip\7z.exe" a -tzip python.zip python
```

#### 8.5. Lambda レイヤーの作成

1. **AWS Management Console**にログインし、**Lambda**サービスに移動します。
2. 左側のメニューから「**レイヤー**」をクリックし、「**レイヤーの作成**」ボタンをクリックします。
3. 「**レイヤーの作成**」画面で以下の項目を入力します。
   - **名前**: `requests-layer`
   - **説明**: 任意の説明を入力します（例：`requestsライブラリを含むレイヤー`）。
   - 「**アップロード**」: 先ほど作成した`python.zip`ファイルをアップロードします。
   - **ランタイム**: `Python 3.8`（使用する Python のバージョンに合わせて選択してください）
4. 「**レイヤーの作成**」ボタンをクリックして、レイヤーを作成します。

#### 8.6. Lambda 関数にレイヤーを追加

1. **Lambda**サービスに移動し、対象の Lambda 関数を選択します。
2. 関数の設定画面で、「**レイヤー**」セクションに移動します。
3. 「**レイヤーの追加**」ボタンをクリックし、以下の項目を設定します。
   - **ランタイムと互換性のあるレイヤーのリストから選択**を選び、先ほど作成した`requests-layer`を選択します。
4. 「**追加**」ボタンをクリックして、レイヤーを Lambda 関数に追加します。

### 9. トレーニングジョブ終了後の Lambda 関数の作成

1. **Lambda 関数の作成**
    - Lambda ダッシュボードに移動し、「**関数の作成**」をクリックします。
	- 「**一から作成**」を選択し、関数名（例: `EndOgiriTrainingJob`）を入力し、ランタイムを Python 3.8 に設定します。
	- 実行ロールには「**既存のロールを使用する**」を選択し、`LambdaEndOgiriTrainingJobRole`を選択します。
	- 「**関数の作成**」をクリックします。

1. **Lambda 関数にコードを追加**
	- 作成した Lambda 関数に以下のコードを追加します。

<details><summary>詳細をクリック</summary>

```python
import json
import boto3
import logging

# CloudWatch Logsの設定
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

sagemaker = boto3.client('sagemaker')

def lambda_handler(event, context):
    try:
        training_job_name = event['detail']['TrainingJobName']
        
        # トレーニングジョブの完了を確認
        if event['detail']['TrainingJobStatus'] != 'Completed':
            logger.error(f"トレーニングジョブ{training_job_name}が正常に完了しませんでした。")
            return {
                'statusCode': 400,
                'body': json.dumps('トレーニングが正常に完了しませんでした。')
            }

        # モデルの作成
        model_name = 'ogiri-model'
        sagemaker.create_model(
            ModelName=model_name,
            PrimaryContainer={
                'Image': '763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:1.6.0-cpu-py36-ubuntu16.04',
                'ModelDataUrl': f"s3://ogiri-training-data-bucket/output/{training_job_name}/output/model.tar.gz"
            },
            ExecutionRoleArn='arn:aws:iam::765231401377:role/SageMakerOgiriTrainingJobRole'
        )

        logger.info("モデルの作成に成功しました。")

        # エンドポイント構成の作成
        endpoint_config_name = 'ogiri-endpoint-config'
        sagemaker.create_endpoint_config(
            EndpointConfigName=endpoint_config_name,
            ProductionVariants=[
                {
                    'VariantName': 'AllTraffic',
                    'ModelName': model_name,
                    'InstanceType': 'ml.m5.large',
                    'InitialInstanceCount': 1
                }
            ]
        )

        logger.info("エンドポイント構成の作成に成功しました。")

        # エンドポイントの作成
        endpoint_name = 'ogiri-endpoint'
        sagemaker.create_endpoint(
            EndpointName=endpoint_name,
            EndpointConfigName=endpoint_config_name
        )

        logger.info("エンドポイントの作成に成功しました。")

        return {
            'statusCode': 200,
            'body': json.dumps('モデルとエンドポイントの作成に成功しました。')
        }
    except Exception as e:
        logger.error(f"予期せぬ例外: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps(f"予期せぬ例外: {str(e)}")
        }
```

</details>
